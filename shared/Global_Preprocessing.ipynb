{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def correct_ampersands(match):\n",
    "    _str = match.group(0)\n",
    "    splitted = re.split('&', _str)\n",
    "    if all([str.isupper(i) for i in splitted]):\n",
    "        return _str\n",
    "    else:\n",
    "        return ' & '.join(splitted)\n",
    "        \n",
    "def correct_multiplemarks(match):\n",
    "    _str = match.group(0)\n",
    "    if _str.startswith('?'):\n",
    "        return '?'\n",
    "    elif _str.startswith('!'):\n",
    "        return '!'\n",
    "        \n",
    "        \n",
    "def correct_slashsplitted(match):\n",
    "    _str = match.group(0)\n",
    "    return ' '.join(' '.join(_str.split('/')).split('\\\\'))\n",
    "\n",
    "        \n",
    "def global_processing(df):\n",
    "    '''\n",
    "    Global preprocessing/data munging\n",
    "    '''\n",
    "    \n",
    "    # remove links\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:re.sub('&amp;*', '&', x), )\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:re.sub('&gt;*', '>', x), )\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:re.sub('&lt;*', '<', x), )\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:re.sub('\\S*&\\S+', correct_ampersands, x), )\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:re.sub('[!?]{2,}', correct_multiplemarks, x), )\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:re.sub('[a-zA-Z]{2,}[\\\\|\\/|\\_][A-Za-z]{2,}', correct_slashsplitted, x), )\n",
    "    df['full_text'] = df['full_text'].apply(lambda x:emoji.get_emoji_regexp().sub('', x), )\n",
    "    \n",
    "    # standardize candidate names/hashtags/mentions\n",
    "    #df['full_text'] = df['full_text'].apply(lambda x:re.sub(\"[B|b]ern\\S*\\s+\", \" BernieSanders \", x))\n",
    "    #df['full_text'] = df['full_text'].apply(lambda x:re.sub(\"\\S*[S|s]ander\\S*\\s+\", \" BernieSanders \", x))\n",
    "    #df['full_text'] = df['full_text'].apply(lambda x:re.sub(\"\\S*[W|w]arren\\S*\\s+\", \" ElizabethWarren \", x))\n",
    "    #df['full_text'] = df['full_text'].apply(lambda x:re.sub(\"\\S*[E|e]lizabeth\\S*\\s+\", \" ElizabethWarren \", x))\n",
    "    #df['full_text'] = df['full_text'].apply(lambda x:re.sub(\"\\S*[B|b]iden\\S*\\s+\", \" JoeBiden \", x))\n",
    "    #df['full_text'] = df['full_text'].apply(lambda x:re.sub(\"\\S*[B|b]iden\\S*\\s+\", \" JoeBiden \", x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_str        22307\n",
       "created_at    19492\n",
       "full_text     23593\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id_str        15714\n",
       "created_at    12774\n",
       "full_text     16747\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id_str        15639\n",
       "created_at    14472\n",
       "full_text     17217\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id_str         int64\n",
       "created_at    object\n",
       "full_text     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in ['Bernie', 'Joe', 'Elizabeth']:\n",
    "    df = pd.read_csv(\"final_dataset_{}.csv\".format(name))\n",
    "    display(df.nunique())\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = global_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decontracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "don't     575\n",
       "it's      530\n",
       "don’t     497\n",
       "it’s      416\n",
       "i’m       379\n",
       "i'm       378\n",
       "you're    297\n",
       "that's    279\n",
       "you’re    272\n",
       "that’s    248\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"[a-zA-Z]{1,7}[\\“|\\’|\\'|\\\"|\\”][a-zA-Z]{1,3}\", x)).dropna().apply(lambda x:x.group(0)).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these dem sens. r running against #trump in #2020elections: \n",
      "\n",
      "- @ewarren \n",
      "- @kamalaharris \n",
      "- @michaelbennet \n",
      "- @amyklobuchar \n",
      "- @corybooker \n",
      "- @berniesanders \n",
      "\n",
      "should these sens. recuse themselves from sitting as a juror at senate #impeachment trial?\n",
      "\n",
      "https://t.co cwchhau5tw\n",
      "\n",
      "--\n",
      ".@ewarren’s granddaughter, lavinia, gives great pep talks.\n",
      "\n",
      "we hope your thanksgiving is filled with friends, family, chosen family, and loved ones who inspire you to keep fighting. https://t.co mwr8aty8oj\n",
      "\n",
      "--\n",
      "democrats doing the “attack the leftist policies” thing should be aware that they are providing bipartisan legitimacy to these talking points. long history of this. @realdonaldtrump will use the attacks against whoever the nominee is, from @joebiden or @petebuttigieg to @ewarren.\n",
      "\n",
      "--\n",
      "@satchelmose @ewarren i can't understand her point. she is claiming the rich are being subsidized by the broader \"we\", but the top 1% pay 37% of federal income taxes and the bottom 50% pay only 3%. what is she saying?\n",
      "\n",
      "--\n",
      "@ewarren “you didn’t build that” remix.  i hated it when obama said it and it sounds even worse when being spewed by a pandering fraud, #fauxcahontas.\n",
      "\n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'][:5].apply(lambda x:print(x, end = '\\n--\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontract(phrase):\n",
    "    \n",
    "    # specific\n",
    "    phrase = re.sub(r\"can[\\’|\\']t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won[\\’|\\']t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"let[\\’|\\']s\", \"let us\", phrase)\n",
    "    \n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n[\\’|\\']t\", \" not\", phrase) #notice the spaces\n",
    "    phrase = re.sub(r\"[\\’|\\']re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"[\\’|\\']s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"[\\’|\\']d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"[\\’|\\']ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"[\\’|\\']t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"[\\’|\\']ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"[\\’|\\']m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from unicodedata import normalize\n",
    "#normalize('NFKD', \"I’m he's they're let's warren's.\\n You will be there _0\").encode('ascii','ignore').decode('utf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(decontract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y’all          25\n",
       "y'all          25\n",
       "ma’am           8\n",
       "your'e          6\n",
       "ma'am           3\n",
       "nat'l           3\n",
       "allowed”is      2\n",
       "his\"bef         2\n",
       "tudents\"wer     2\n",
       "ne'er           2\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"[a-zA-Z]{1,7}[\\“|\\’|\\'|\\\"|\\”][a-zA-Z]{1,3}\", x)).dropna().apply(lambda x:x.group(0)).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these dem sens. r running against #trump in #2020elections: \n",
      "\n",
      "- @ewarren \n",
      "- @kamalaharris \n",
      "- @michaelbennet \n",
      "- @amyklobuchar \n",
      "- @corybooker \n",
      "- @berniesanders \n",
      "\n",
      "should these sens. recuse themselves from sitting as a juror at senate #impeachment trial?\n",
      "\n",
      "https://t.co cwchhau5tw\n",
      "\n",
      "--\n",
      ".@ewarren is granddaughter, lavinia, gives great pep talks.\n",
      "\n",
      "we hope your thanksgiving is filled with friends, family, chosen family, and loved ones who inspire you to keep fighting. https://t.co mwr8aty8oj\n",
      "\n",
      "--\n",
      "democrats doing the “attack the leftist policies” thing should be aware that they are providing bipartisan legitimacy to these talking points. long history of this. @realdonaldtrump will use the attacks against whoever the nominee is, from @joebiden or @petebuttigieg to @ewarren.\n",
      "\n",
      "--\n",
      "@satchelmose @ewarren i can not understand her point. she is claiming the rich are being subsidized by the broader \"we\", but the top 1% pay 37% of federal income taxes and the bottom 50% pay only 3%. what is she saying?\n",
      "\n",
      "--\n",
      "@ewarren “you did not build that” remix.  i hated it when obama said it and it sounds even worse when being spewed by a pandering fraud, #fauxcahontas.\n",
      "\n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'][:5].apply(lambda x:print(x, end = '\\n--\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   https://t.co\n",
       "1                   https://t.co\n",
       "8                   https://t.co\n",
       "14                  https://t.co\n",
       "15                  https://t.co\n",
       "                  ...           \n",
       "12180    https://t.co/v7d0thdr8b\n",
       "12187               https://t.co\n",
       "12192               https://t.co\n",
       "12199    https://t.co/b4rqwmi3lp\n",
       "12213               https://t.co\n",
       "Name: full_text, Length: 1918, dtype: object"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\w*(t\\.co|http)\\S*\", x)).dropna().apply(lambda x:x.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(phrase):\n",
    "    \n",
    "    phrase = re.sub(\"\\S*(t\\.co|http)\\S*\", \"\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: full_text, dtype: object)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\S*(t\\.co|http)\\S*\", x)).dropna().apply(lambda x:x.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21411"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\@\\w+\", x)).dropna().apply(lambda x:x.group(0)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@ewarren            9075\n",
       "@saracarterdc        316\n",
       "@proudresister       280\n",
       "@berniesanders       180\n",
       "@joebiden            102\n",
       "                    ... \n",
       "@birdie4bernie20       1\n",
       "@beeluvedb             1\n",
       "@nickuniejewski        1\n",
       "@peacekeeper2019       1\n",
       "@therisingkn1ght       1\n",
       "Name: full_text, Length: 3361, dtype: int64"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\@\\w+\", x)).dropna().apply(lambda x:x.group(0)).str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(phrase):\n",
    "    \n",
    "    phrase = re.sub(\"\\@ewarren\", \"\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@proudresister      317\n",
       "@saracarterdc       316\n",
       "@berniesanders      294\n",
       "@teamwarren         253\n",
       "@joebiden           124\n",
       "                   ... \n",
       "@maryvictoryfarm      1\n",
       "@senategop            1\n",
       "@rollieg2             1\n",
       "@nofascistlies        1\n",
       "@foxeesrldy           1\n",
       "Name: full_text, Length: 3530, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\@\\w+\", x)).dropna().apply(lambda x:x.group(0)).str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21411, 3)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_spammy = df['full_text'].apply(lambda x:re.search(\"(\\@.*){5,}\", x)).dropna().apply(lambda x:x.group(0)).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3133"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_spammy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[[i for i in df.index if i not in index_spammy]].reindex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#warren2020                           156\n",
       "#teamwarren                            43\n",
       "#elizabethwarren                       35\n",
       "#winwithwarren                         19\n",
       "#warren                                13\n",
       "#neverwarren                            7\n",
       "#allinforwarren                         6\n",
       "#warrensinsaneclownposse                3\n",
       "#presidentelizabethwarren               3\n",
       "#catsforwarren                          2\n",
       "#warrenisafool                          2\n",
       "#womenwithwarren                        2\n",
       "#weakwarren                             2\n",
       "#chicagoforwarren                       2\n",
       "#warren4me                              2\n",
       "#ilforwarren                            2\n",
       "#madampresidentwarren                   2\n",
       "#presidentwarren                        2\n",
       "#wearwarren                             2\n",
       "#warrenmemeteam                         2\n",
       "#warren20never                          2\n",
       "#wiforwarren                            2\n",
       "#elizabethwarren2020                    2\n",
       "#atlantawithwarren                      2\n",
       "#warrendonor                            2\n",
       "#dogsforwarren                          2\n",
       "#wrongagainwarren                       2\n",
       "#warrensanders                          2\n",
       "#warrencastro2020                       2\n",
       "#opestatesforwarren                     2\n",
       "#kushnerforwarren2020                   1\n",
       "#switchtowarren                         1\n",
       "#elizbethwarrenliesabouteverything      1\n",
       "#warrenweekend                          1\n",
       "#warrenwillneverbepresident             1\n",
       "#nc4warren                              1\n",
       "#whichwarren                            1\n",
       "#endwarren                              1\n",
       "#warreninchicago                        1\n",
       "#dropoutwarren                          1\n",
       "#warrendemocrats                        1\n",
       "#warrentellthetruth                     1\n",
       "#registervotesanderswarren2020          1\n",
       "#impeachwarren                          1\n",
       "#dorksforwarren                         1\n",
       "#wallstwarren                           1\n",
       "#warhawkwarren                          1\n",
       "#ewarren                                1\n",
       "#isupportelizabethwarren                1\n",
       "#elizabethwarrenis39                    1\n",
       "#gohomewarren                           1\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\#\\w*warren\\w*\", x)).dropna().apply(lambda x:x.group(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(phrase):\n",
    "\n",
    "    for i in ['#warren2020', '#teamwarren', '#elizabethwarren', '#winwithwarren', '#warren']:\n",
    "        phrase = re.sub(i, \"\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#neverwarren                          7\n",
       "#allinforwarren                       6\n",
       "#presidentelizabethwarren             3\n",
       "#iwannabelikewarren                   2\n",
       "#madampresidentwarren                 2\n",
       "#opestatesforwarren                   2\n",
       "#ilforwarren                          2\n",
       "#chicagoforwarren                     2\n",
       "#atlantawithwarren                    2\n",
       "#rolloverwarren                       2\n",
       "#dogsforwarren                        2\n",
       "#catsforwarren                        2\n",
       "#wiforwarren                          2\n",
       "#weakwarren                           2\n",
       "#poetsforwarren                       2\n",
       "#wrongagainwarren                     2\n",
       "#ohioforwarren                        2\n",
       "#womenwithwarren                      2\n",
       "#fl4warren                            2\n",
       "#wearwarren                           2\n",
       "#presidentwarren                      2\n",
       "#elizbethwarrenliesabouteverything    1\n",
       "#kushnerforwarren2020                 1\n",
       "#nc4warren                            1\n",
       "#isupportelizabethwarren              1\n",
       "#poc4warren                           1\n",
       "#illinoiswithwarren                   1\n",
       "#gohomewarren                         1\n",
       "#switchtowarren                       1\n",
       "#registervotesanderswarren2020        1\n",
       "#dorksforwarren                       1\n",
       "#impeachwarren                        1\n",
       "#dropoutwarren                        1\n",
       "#endwarren                            1\n",
       "#wallstwarren                         1\n",
       "#warhawkwarren                        1\n",
       "#ewarren                              1\n",
       "#whichwarren                          1\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\#\\w*warren\\w*\", x)).dropna().apply(lambda x:x.group(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Obvious) Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " elizabeth         209\n",
       "  elizabeth         27\n",
       " \\n\\nelizabeth       3\n",
       "\\n\\nelizabeth        2\n",
       " elizabeth\\n         2\n",
       " \\nelizabeth         2\n",
       "  elizabeth          1\n",
       "   elizabeth         1\n",
       "\\n elizabeth         1\n",
       "\\nelizabeth          1\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+\\w*elizabeth\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warren        1405\n",
       "teamwarren     318\n",
       "senwarren      114\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"(team|sen)*warren\", x)).dropna().apply(lambda x:x.group(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28        \n",
       "31        \n",
       "32        \n",
       "38        \n",
       "47        \n",
       "        ..\n",
       "21356     \n",
       "21362     \n",
       "21366     \n",
       "21367     \n",
       "21372     \n",
       "Name: full_text, Length: 1837, dtype: object"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"(team|sen)*warren\", x)).dropna()\\\n",
    ".apply(lambda x:re.sub(\"(team|sen)*warren\", \"\", x.group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(phrase):\n",
    "    \n",
    "    phrase = re.sub(\"\\s+\\w*elizabeth\\w*\\s+\", \"\", phrase)\n",
    "    phrase = re.sub(\"(team|sen)*warren\", \"\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: full_text, dtype: int64)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+\\w*elizabeth\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: full_text, dtype: int64)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"(team|sen)*warren\", x)).dropna().apply(lambda x:x.group(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_final_Elizabeth.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' bernie ', '  bernie ', ' berners\\n', '\\n\\nbernie ', ' bernie\\n',\n",
       "       ' bernie \\n', '\\nbernie ', ' bern ', ' \\n\\nbernie ', ' bernanke ',\n",
       "       ' bernie  ', ' bernese ', ' berniebros\\n', ' berners '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+[B|b]ern\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' sanders ', ' sander ', '  sanders ', ' sanderswarren ',\n",
       "       '\\n\\nsanders ', ' sanders\\n', ' \\nsanders '], dtype=object)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+[S|s]ander\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' warren ', ' warren\\n', '  warren ', ' \\nwarren ', '\\n\\nwarren ',\n",
       "       ' warren \\n', ' warrensanders ', ' warren\\n\\n', '\\nwarren ',\n",
       "       ' warrens ', ' warren   \\n', ' warren  \\n', '  warren\\n',\n",
       "       '    warren ', '   warren ', ' warren  '], dtype=object)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+[W|w]arren\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' elizabeth ', ' elizabeth\\n', '  elizabeth ', '\\n\\nelizabeth ',\n",
       "       ' \\n\\nelizabeth ', '  \\n\\nelizabeth ', '   elizabeth ',\n",
       "       '\\n elizabeth ', ' \\nelizabeth ', '  elizabeth  ', '\\nelizabeth '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+[E|e]lizabeth\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' biden ', ' bidens ', ' bidenville \\n\\n', ' biden \\n', '  biden ',\n",
       "       '\\n\\nbiden '], dtype=object)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s+[B|b]iden\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['biden ', 'biden\\n', 'biden  ', 'biden \\n\\n', 'biden2020 ',\n",
       "       ' biden ', 'biden    ', 'biden \\n', 'biden\\n\\n', 'biden  \\n\\n',\n",
       "       ' bidens ', 'bidenbrigade ', 'bidenbrigade  ', ' bidenville \\n\\n',\n",
       "       'biden2020\\n', ' biden \\n', 'biden2020 \\n', 'biden   \\n',\n",
       "       'biden \\n \\n', '  biden ', 'biden\\n ', '\\n\\nbiden '], dtype=object)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search(\"\\s*[B|b]iden\\w*\\s+\", x)).dropna().apply(lambda x:x.group(0)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['strom_annette', 'foundation/chinese', 'colo_trumpette',\n",
       "       'brock_mchugebig', 'alyssa_milano', 'bernard_cecilia',\n",
       "       'warren/bernie', 'republicans/ruskies', 'credits/packet',\n",
       "       'aged_and', 'nick_zen', 'teacher/professor', 'jim_jordan',\n",
       "       'see/hear', 'man/husband', 'australia/canada', 'space_expln',\n",
       "       'morning_joe', 'jamie_crane', 'angelo_back', 'armon_dillo',\n",
       "       'nasty_woman', 'thetruth_tx', 'millionaires/billionaires',\n",
       "       'anders_aslund', 'agnes_gibboney', 'make/amend', 'pibble_racingdc',\n",
       "       'pharma/healthcare', 'news/bad', 'lin_manuel', 'rich_indestin',\n",
       "       'fact/abuses', 'life/liberty', 'wade_snowden', 'poormans_word',\n",
       "       'andresha_bass', 'jimmy_dore', 'healthcare/climate', 'mboksr_maga',\n",
       "       'mel_faith', 'debra_hendler', 'rock_valkyrie', 'laurent_weppe',\n",
       "       'helen_manfred', 'mn_for', 'naep_nces', 'wendy_soxy', 'bee_dottie',\n",
       "       'unrest_mag', 'ciaag_lauren', 'trump/putin', 'abogado_avocado',\n",
       "       'nico_lang', 'funding/enforcing', 'joy_american', 'loans/grants',\n",
       "       'obama/biden', 'students_warren', 'nj_politics', 'no_silenced',\n",
       "       'liberal/socialist', 'amy_siskind', 'ish_the', 'foe_us',\n",
       "       'sheriff_lvmpd', 'pj_hurt', 'john_etienne', 'timi_okb',\n",
       "       'eric_kleppel', 'nevar_alaya', 'dad_darius', 'farm_machinery',\n",
       "       'bold_francesco', 'css_sporklab', 'eric_cha', 'farr_mimi',\n",
       "       'usa_anne', 'hopper_atl', 'accidental_tica', 'naacp_ldf',\n",
       "       'warren/harris', 'mr_shaktus', 'khyre_edwards',\n",
       "       'benefits/benefited', 'city/location', 'real_the', 'urself/ur',\n",
       "       'adam_kreiser', 'dad_safety', 'prd_perspective', 'conserv_tribune',\n",
       "       'kerry/obama', 'mr_ankrum', 'do/say', 'ap_politics',\n",
       "       'cara_doxyluv', 'howz_my', 'greg_ayiman', 'politics_polls',\n",
       "       'david_desj', 'grey_goose', 'harris/castro', 'meg_lama', 'door_no',\n",
       "       'who_knows', 'op_omom', 'reuters/ipsos', 'bernese/shepherd',\n",
       "       'sanders/warren', 'do_rand', 'aesthetics_ko', 'zuckerberg/corp',\n",
       "       'bernie/warren', 'unitehere_sofla', 'reality_du', 'badluck_jones',\n",
       "       'frank_schaeffer', 'amy_riveter', 'usaid_haiti', 'rope_sand',\n",
       "       'web_rant', 'play_grow', 'reins/budget', 'nicole_bertrand',\n",
       "       'gabriel_zucman', 'shopping/cooking', 'the_foreclosure',\n",
       "       'bayou_bengals', 'david_darmofal', 'queen_europe',\n",
       "       'averill_bowers', 'curly_woowoowoo', 'the_john', 'made_in',\n",
       "       'etui_org', 'kickass_sushi', 'mick_jones', 'karma_down',\n",
       "       'mediocrity/status', 'adrienne_dnc', 'pr_souza', 'hitman_rickytan',\n",
       "       'tim_cook', 'rankin_brady', 'heidi_cuda', 'ceraldi_carleen',\n",
       "       'socialist/communist', 'twin_blue', 'rising_serpent',\n",
       "       'blk_intellect', 'the_hindu', 'todd_butler', 'pablo_honey',\n",
       "       'bush/trump', 'dewhirst_wvd', 'honest_irish', 'security/medicare',\n",
       "       'democrats/unions', 'notorious_hbg', 'lee_gsc', 'joanna_resists',\n",
       "       'his_majesty', 'frankie_dash', 'jstein_wapo',\n",
       "       'states/congressional', 'michael_epps', 'man_bear',\n",
       "       'diplomatic/did', 'rosie_life', 'jack_ahearn', 'peace_nh',\n",
       "       'amjad_alkadri', 'alex_connect', 'understand/realize',\n",
       "       'ee_carroll', 'mcquee_scott', 'dems/media', 'waitingomths/years',\n",
       "       'meme_war', 'early/mid', 'undermine/game', 'iphone_news',\n",
       "       'jerry_kersey', 'doc_hollidaypt', 'many/most', 'jersey_craig',\n",
       "       'preserving_usa', 'as_thechamp', 'tax/gross', 'experiences/burn',\n",
       "       'maternity/paternity', 'chale_usa', 'rly_tattooed', 'marty_walsh',\n",
       "       'esu_sda', 'judges/scotus', 'owns/maintains', 'storyy_loves',\n",
       "       'fuego_marc', 'professor/politician', 'krazy_kris',\n",
       "       'himself/herself', 'dawg_bubba', 'og_synged', 'chris_scott',\n",
       "       'occupyradio_net', 'franklin_graham', 'and/or',\n",
       "       'electricity/water', 'his/her', 'goods/services', 'doctors/nurses',\n",
       "       'pickupthe_phone', 'optimal_max', 'state/society', 'good/service',\n",
       "       'brad_polumbo', 'nate_cohn', 'rp_kearney', 'yur_best',\n",
       "       'kevin_shipp', 'shotgun_pi', 'poor/middle', 'she/her',\n",
       "       'ss/medicare', 'forward/wait', 'congress/senate', 'deplorable_man',\n",
       "       'socialism/communism', 'kate_lucas', 'answer/relay',\n",
       "       'ideas/policies', 'provide/create', 'refugees/immigrants',\n",
       "       'sari_diplonerd', 'wage/benefits', 'mentor/bestie',\n",
       "       'general_hopkins', 'sunny_hundal', 'zach_graumann', 'road_warrior',\n",
       "       'ammo_irl', 'house/armory', 'mfa_russia', 'mature/lateral',\n",
       "       'rally/town', 'verano_frio', 'dave_willford', 'sassie_lassie',\n",
       "       'nuzum_curt', 'lady_laura', 'grants/taxpayers', 'davies_eric',\n",
       "       'economist/yougov', 'affordable/free', 'run/own', 'spam/fake',\n",
       "       'van_ruin', 'ca_for', 'incarcerated_et', 'eli_debenham',\n",
       "       'econ_marshall', 'tammy_beth', 'tore_says', 'satirist_indian',\n",
       "       'mandy_puremi', 'yotes_lesgo', 'eldon_katz', 'harris/buttigieg',\n",
       "       'jenees_is', 'jacob_frey', 'xr_nyc', 'scott_waddell', 'mikes_booh',\n",
       "       'fancybitch_here', 'the_lone', 'birthday/thanksgiving',\n",
       "       'low/middle', 'town/state', 'drty_brd', 'irongeek_adc',\n",
       "       'ann_cannon', 'donna_knight', 'el_daverino', 'domini_templari',\n",
       "       'lis_smith', 'keathley_penny', 'sonny_scroggins', 'to_be',\n",
       "       'yomptons_finest', 'jg_noplanet', 'warren/sanders', 'sam_adeyemi',\n",
       "       'native/indigenous', 'business/economy', 'god_speedusa',\n",
       "       'azscorpion_tail', 'risk/reward', 'sam_schulman', 'mrjones_tm',\n",
       "       'if/when', 'freeloaders/illegals', 'dawn_demore', 'bos_imm',\n",
       "       'ignite_national', 'smedley_butler', 'davidwright_cnn',\n",
       "       'cost/benefit', 'official/state', 'left_firebrand', 'net_enforcer',\n",
       "       'lovewave_sw', 'zoltan_istvan', 'two/three', 'joel_haokip',\n",
       "       'nationalist/populist', 'luv_me', 'workforce/service',\n",
       "       'tempestuous_tea', 'prof_infierno', 'headlines_see',\n",
       "       'vintage_bridge', 'thom_hartmann', 'public_citizen',\n",
       "       'the_campaign', 'cam_rod', 'mortgages/rents', 'misogynist/gop',\n",
       "       'columbia_review', 'kw_sagan', 'ohio_buckeye', 'democrat_texas',\n",
       "       'leaders/executives', 'cj_disabledvet', 'bank_of',\n",
       "       'cringe_general', 'dj_rylas', 'davis_again', 'angry_cs',\n",
       "       'ice_markets', 'dana_tfsj', 'gambino_suzanne', 'mikes_photoshop',\n",
       "       'steve_troxel', 'sessions/devilmorin', 'trump/republican',\n",
       "       'nigel_farage', 'sophie_rose', 'touring/defending',\n",
       "       'carolina_girl', 'stealth_patriot', 'city_spaces',\n",
       "       'lumiere_pacific', 'kayode_ani', 'rogue_of', 'artist_qu',\n",
       "       'jamie_agust', 'lil_miss', 'dr_tankodc', 'anxious_xtravrt',\n",
       "       'mcmillin_kelli', 'besa_sabe', 'david_feldman', 'dallas_waid',\n",
       "       'treating/bandaging', 'american_baby', 'jason_pontin',\n",
       "       'dawn_switch', 'marx_attacks', 'patriot_billy', 'its_happening',\n",
       "       'da_stockman', 'accessible/least', 'african/american',\n",
       "       'bama_barack', 'cycle_logical', 'docta_ash',\n",
       "       'indebtedness/servitude', 'dentists/eye', 'tadea_nicole',\n",
       "       'cdn_dimension', 'krs_rogueshark', 'dadbod_thor', 'rn_deplorable',\n",
       "       'steve_flesch', 'social/media', 'todd_fashion', 'heidi_parton',\n",
       "       'our_da', 'heroin/fentanyl', 'justice_healing', 'red/white',\n",
       "       'virtual_prof', 'dispensary/shop', 'brian_onright', 'mr_thriven',\n",
       "       'sob_er', 'deepa_shivaram', 'bobbi_egan', 'mrs_malindo',\n",
       "       'seattle/bellevue', 'bobbie_gerry', 'lildevil_dani', 'mr_joewhite',\n",
       "       'sarah_alice', 'exams/tests', 'loved/not', 'mare_carl',\n",
       "       'cbs_herridge', 'xenos_rifs', 'dan_march', 'mre_bolivia',\n",
       "       'earthgurl_kmac', 'frenetic/terrible', 'drew_brosenhaus',\n",
       "       'nicholas_john', 'calvo_csquared', 'hiv/aids', 'flares/swelling',\n",
       "       'you/warren', 'michael_dxtr', 'law/rule', 'ralph_breeden',\n",
       "       'anonyms_one', 'fl_lewoo', 'virgins/lgbtq', 'houses/commercial',\n",
       "       'checks/balances', 'hiker_ix', 'jay_nelson', 'housing/lending',\n",
       "       'mcconnell/cruz', 'puffy_cloud', 'grey_books', 'tex_ican',\n",
       "       'dan_geldon', 'david_cameron', 'owners/risk', 'rancho_steve',\n",
       "       'prof_kennedy', 'ohio_politics', 'babcock_ian', 'nance_pc',\n",
       "       'az_jaime', 'aaronious_monk', 'threader_app', 'thorn_king',\n",
       "       'ag_due', 'liberals/moderates', 'sabine_durden',\n",
       "       'socialist/communistic', 'husband/father', 'canada/france',\n",
       "       'secluding/killing', 'cooking/laughing', 'benefits/vacation',\n",
       "       'harry_janner', 'sarahlynn_eh', 'websites/fox', 'un_hrc',\n",
       "       'neo_noto', 'democratic_nomination', 'fsu_noles', 'mitch_osborne',\n",
       "       'fossil_free', 'was/has', 'hispanic/native', 'real_arian',\n",
       "       'grandma_cam', 'shawna_morlock', 'repairing/replacing', 'ht_ic',\n",
       "       'devon_mfa', 'ismwatcher_up', 'was/is', 'ms_gottie',\n",
       "       'katalin_pota', 'smarter_iam', 'hk_watch', 'resist_detroit',\n",
       "       'scott_calmes', 'maya_slaughter', 'shine_allfosh', 'patrick_weill',\n",
       "       'cj_isnowblue', 'sr_montrell', 'babe_in', 'prog_blacksmith',\n",
       "       'heart_lies', 'brian_riccio', 'arden_bracewell', 'wealth/income',\n",
       "       'jason_pelletier', 'dolphin_tj', 'warren/abrams', 'umbra_vox',\n",
       "       'on_the', 'provider/doctor', 'kids/grandkids', 'culture/nation',\n",
       "       'warren/klobochar', 'cbot/chicago', 'crime/corruption',\n",
       "       'mcw_disruptor', 'kort_rob', 'fair/reasonable', 'clinton/honduras',\n",
       "       'us_fda', 'statedept_cio', 'afdc/chip', 'alex_segura',\n",
       "       'kath_krueger', 'rotunda_rotunda', 'thoughtful/respectful',\n",
       "       'hard/fast', 'lily_nea', 'magnifikat_st', 'not_that', 'nar_olepsy',\n",
       "       'silver_fox', 'jamie_ducharme', 'marla_kilfoyle',\n",
       "       'defender/promoter', 'peace_of', 'remys_dad', 'steve_mutch',\n",
       "       'harvard/yale', 'yomiuri_online', 'monty_loyd', 'gregabbott_tx',\n",
       "       'support/funding', 'nationalist_kag', 'holistic_hottie',\n",
       "       'voices/work', 'teli_guy', 'republican/trump', 'diputados_bol',\n",
       "       'theofficial_tfn', 'teo_dor', 'history/politics', 'wilkinson_josh',\n",
       "       'peterdutton_mp', 'capitalism/conservatism', 'cristina_gw',\n",
       "       'when/where', 'consumer/capital', 'mandy_pantz',\n",
       "       'president/candidate', 'paying/receivng', 'narrative/biography',\n",
       "       'stern_man', 'king_marmot', 'jonestown/heavens', 'tax/money',\n",
       "       'steele_axelrod', 'yale/harvard', 'immigrant/woc', 'enjoy_the',\n",
       "       'gene_lasecki', 'libby_mulligan', 'smart_ass', 'indigo_ebony',\n",
       "       'beanies_masato', 'chelsea_nordick', 'george_revutsky',\n",
       "       'kurtis_wu', 'matt_cam', 'needle_of', 'longhrn_nation',\n",
       "       'muslim_aid', 'claire_ullman', 'freedom_latinas', 'surf_key',\n",
       "       'national_polls', 'professional/political', 'bakari_sellers',\n",
       "       'vander_vero', 'tribes/areas', 'iran/syrai', 'been/still',\n",
       "       'nada_lemming', 'think/hope', 'analysis/facts', 'digital_pimp',\n",
       "       'will/should', 'gee_eddie', 'michaels_grind', 'walk/talk',\n",
       "       'shareholder/board', 'get/got', 'chels_roy', 'carol_morehead',\n",
       "       'paul_taske', 'nutt_kt', 'brewer_rb', 'nyc_erik', 'the_sioux',\n",
       "       'muth_carol', 'virginia_aflcio', 'kaitlin_benz', 'cov_gretchen',\n",
       "       'choo_ek', 'math/reality', 'cam_joseph', 'russia/assrump',\n",
       "       'jim_pettit', 'am_prohuman', 'democrat/liberal', 'men/ex',\n",
       "       'raj_of', 'fence/border', 'amato_joe', 'organizers/vols',\n",
       "       'economic/wealth', 'geoff_ginter', 'whisky_frank', 'baylee_hodges',\n",
       "       'youth/the', 'cocoa_bean', 'knowledge/exp', 'steffen_finch'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'].apply(lambda x:re.search('[a-zA-Z]{2,}[\\\\|\\/|\\_][A-Za-z]{2,}', x)).dropna().apply(lambda x:x.group(0)).unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a b c'"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(' '.join('a/b\\c'.split('/')).split('\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "funct = lambda a:a*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funct(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
